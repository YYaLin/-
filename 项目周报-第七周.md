# 项目周报

**日期**：2025-5-25
**项目实践题目**：面向机器学习的数据清洗方法

## 实践内容
### 论文代码
**模拟标签分布**
```python
# 模拟标签分布
class LabelDistribution:
    def __init__(self, num_classes):
        self.num_classes = num_classes
        self.label_counts = np.zeros(num_classes)
        self.distribution = np.ones(num_classes) / num_classes
        self.random_state = np.random.RandomState(42) 
    
    def update_distribution(self, labels):
        unique, counts = np.unique(labels, return_counts=True)
        self.label_counts[unique] += counts
        self.distribution = self.label_counts / self.label_counts.sum()
    
    def sample_labels(self, size):
        return self.random_state.choice(
            self.num_classes,
            size=size,
            p=self.distribution
        )
```

**记录结果**
```python
#输出信息
class SimulationStats:
    def __init__(self):
        self.iterations = 0
        self.accuracy = []
        self.precision = []
        self.recall = []
        self.f1_score = []
        self.selected_counts = []
    
    def update(self, accuracy, precision, recall, f1, selected):
        self.iterations += 1
        self.accuracy.append(accuracy)
        self.precision.append(precision)
        self.recall.append(recall)
        self.f1_score.append(f1)
        self.selected_counts.append(selected)
```

**样本选择器**
```python
class BaseSelector:
    def select_samples(self, labels, budget):
        raise NotImplementedError

class ActiveLabelSelector(BaseSelector):
    def __init__(self, model):
        self.model = model.to(torch.device("cuda" if torch.cuda.is_available() else "cpu"))
    
    def select_samples(self, dataloader, budget, noisy_labels=None):
        #评分函数 Φ = 交叉熵（噪声）- 熵（难度），选择评分最高的样本
        self.model.eval()
        ce_scores = []  # 交叉熵（噪声分数）
        entropy_scores = []  # 熵（难度分数）
        device = next(self.model.parameters()).device
        
        with torch.no_grad():
            for i, (images, labels) in enumerate(dataloader):
                images = images.to(device)
                outputs = self.model(images)
                probs = F.softmax(outputs, dim=1)
                
                # 计算交叉熵（CE）：-log(p(y|x))，y为真实的噪声标签
                if noisy_labels is not None:
                    # 获取当前批次的噪声标签
                    batch_size = images.size(0)
                    start_idx = i * batch_size
                    end_idx = min(start_idx + batch_size, len(noisy_labels))
                    batch_noisy_labels = torch.tensor(noisy_labels[start_idx:end_idx]).to(device)
                    
                    # 计算交叉熵
                    ce = -torch.log(probs[torch.arange(len(batch_noisy_labels)), batch_noisy_labels] + 1e-8)
                else:
                    # 如果没有提供噪声标签，使用模型预测的伪标签
                    pseudo_labels = probs.argmax(dim=1)
                    ce = -torch.log(probs[torch.arange(len(pseudo_labels)), pseudo_labels] + 1e-8)
                
                ce_scores.extend(ce.cpu().numpy())
                
                # 计算熵（H）：-Σp(c|x)log(p(c|x))
                entropy = -torch.sum(probs * torch.log(probs + 1e-8), dim=1)
                entropy_scores.extend(entropy.cpu().numpy())
        
        # 综合评分：CE-H（论文公式2）
        scores = np.array(ce_scores) - np.array(entropy_scores)
        selected_indices = np.argsort(-scores)[:budget]  # 降序排列，选前budget个
        return selected_indices

class RandomSelector(BaseSelector):
    def select_samples(self, labels, budget):
        return np.random.choice(len(labels), size=budget, replace=False)
```

**数据选择器**
```python
#数据选择器
class DataCurationSimulator:
    def __init__(self, initial_labels, label_distribution, 
                 relabel_budget, sample_selector, trainer, train_images, noisy_labels=None, confidence_threshold=0.6):
        self.current_labels = initial_labels  # 初始标签（one-hot编码）
        self.label_distribution = label_distribution  # 真实标签分布
        self.relabel_budget = relabel_budget  # 每次迭代重新标记预算
        self.selector = sample_selector  # 样本选择器
        self.trainer = trainer  # 训练器
        self.train_images = train_images  # 训练图像数据
        self.global_stats = SimulationStats()  # 统计信息
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.noisy_labels = noisy_labels  # 真实的噪声标签
        self.confidence_threshold = confidence_threshold  # 置信度阈值

    def run_simulation(self, test_loader=None, max_iterations=5):
        for i in range(max_iterations):
            print(f"--------第{i + 1}次清洗--------")
            # 1. 选择需要重新标记的样本
            current_labels = self.current_labels.argmax(axis=1)
            if isinstance(self.selector, ActiveLabelSelector):
                # 创建一个新的DataLoader，包含当前的标签
                train_dataset = [(img, current_labels[i].item()) for i, img in enumerate(self.train_images)]
                train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False)

                # 如果有真实的噪声标签，传递给选择器
                if self.noisy_labels is not None:
                    selected_indices = self.selector.select_samples(
                        train_loader, self.relabel_budget, self.noisy_labels
                    )
                else:
                    selected_indices = self.selector.select_samples(train_loader, self.relabel_budget)

            else:
                selected_indices = self.selector.select_samples(current_labels, self.relabel_budget)

            # 2. 模拟重新标记过程（根据模型置信度）
            self.trainer.model.eval()
            low_confidence_indices = []
            with torch.no_grad():
                for idx in selected_indices:
                    image = self.train_images[idx].unsqueeze(0).to(self.device)
                    output = self.trainer.model(image)
                    probs = F.softmax(output, dim=1)
                    confidence = probs.max().item()
                    if confidence < self.confidence_threshold:
                        low_confidence_indices.append(idx)

            if low_confidence_indices:
                new_labels = self.label_distribution.sample_labels(len(low_confidence_indices))
                self.current_labels[low_confidence_indices] = np.eye(self.current_labels.shape[1])[new_labels]

            # 3. 构建清洗后的数据集并训练模型
            cleaned_labels = self.current_labels.argmax(axis=1)
            cleaned_dataset = [(img, cleaned_labels[i].item()) for i, img in enumerate(self.train_images)]
            cleaned_loader = DataLoader(cleaned_dataset, batch_size=128, shuffle=True)
            self.trainer.train(cleaned_loader)

            # 4. 在测试集上评估模型
            if test_loader:
                preds = self.trainer.predict(test_loader)
                accuracy = accuracy_score(test_loader.dataset.targets, preds)
                precision = precision_score(test_loader.dataset.targets, preds, average='macro')
                recall = recall_score(test_loader.dataset.targets, preds, average='macro')
                f1 = f1_score(test_loader.dataset.targets, preds, average='macro')

                self.global_stats.update(
                    accuracy=accuracy,
                    precision=precision,
                    recall=recall,
                    f1=f1,
                    selected=len(selected_indices)
                )

            # 更新标签分布
            self.label_distribution.update_distribution(cleaned_labels)
```
**主动标签清洗器**
```python
class ActiveLabelCleaner:
    def __init__(self, trainer, dataloader, noisy_labels, relabel_budget, train_images, selector_type='cross_entropy'):
        self.trainer = trainer
        self.dataloader = dataloader
        self.noisy_labels = noisy_labels
        self.relabel_budget = relabel_budget
        self.train_images = train_images
        
        if hasattr(trainer, 'model1') and hasattr(trainer, 'model2'):
            self.selector = ActiveLabelSelector(trainer.model1)
        else:
            self.selector = ActiveLabelSelector(trainer.model)

    
    def clean(self, test_loader, max_iterations=5):
        # 初始化标签分布
        num_classes = 10
        label_dist = LabelDistribution(num_classes)
        
        # 初始化模拟器
        initial_labels = np.eye(num_classes)[self.noisy_labels.numpy()]  # one-hot编码
        simulator = DataCurationSimulator(
            initial_labels=initial_labels,
            label_distribution=label_dist,
            relabel_budget=self.relabel_budget,
            sample_selector=self.selector,
            trainer=self.trainer,
            train_images=self.train_images,
            noisy_labels=self.noisy_labels.numpy()  
        )
        
        # 运行模拟
        simulator.run_simulation(max_iterations=max_iterations, test_loader=test_loader)
        
        # 获取清洗后的标签
        cleaned_labels = simulator.current_labels.argmax(axis=1)
        self.simulator = simulator  # 保存模拟器用于统计
        return cleaned_labels
```
### 主函数
```python
# 数据预处理
transform_train = transforms.Compose([
    transforms.Resize(128),
    transforms.RandomHorizontalFlip(),
    transforms.RandomVerticalFlip(),
    transforms.RandomRotation(30),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
transform_test = transforms.Compose([
    transforms.Resize(128),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# 加载CIFAR10数据集
full_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)

# 划分训练集和验证集（80%训练，20%验证）
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_data, val_data = random_split(full_dataset, [train_size, val_size])

# 生成带噪声的训练标签
train_images = [data[0] for data in train_data]
true_labels = torch.tensor([data[1] for data in train_data])
noisy_labels = true_labels.clone()
noise_rate = 0.3
n_noisy = int(len(noisy_labels) * noise_rate)
noisy_indices = torch.randperm(len(noisy_labels))[:n_noisy]
for idx in noisy_indices:
    # 随机替换为其他类别标签
    new_label = torch.randint(0, 10, (1,))
    while new_label == noisy_labels[idx]:
        new_label = torch.randint(0, 10, (1,))
    noisy_labels[idx] = new_label

# DataLoader
train_dataset = [(img, label.item()) for img, label in zip(train_images, noisy_labels)]
train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)

# 实验配置
seed = 42
torch.manual_seed(seed)
np.random.seed(seed)
relabel_budget = int(len(train_dataset) * noise_rate * 2)  # 预算设置为噪声样本的2倍
techniques = {
    'Vanilla': VanillaTrainer(),
    'CoTeaching': CoTeachingTrainer(),
    'ELR': ELRTrainer(len(train_dataset))
}

results = {}
before_cleaning = {}
for name, trainer in techniques.items():
    # if(name == 'Vanilla'): continue
    # if(name == 'CoTeaching'): continue
    # if(name == 'ELR'): continue
    print("--------{name}--------".format(name=name))

    # 初始训练（带噪声标签）
    trainer.train(train_loader)
    preds = trainer.predict(test_loader)
    before_acc = accuracy_score(test_dataset.targets, preds)
    before_cleaning[name] = before_acc
    print(f"[{name}] 清洗前准确率: {before_acc:.4f}")
    
    print("--------[{name}]主动标签清洗--------".format(name=name))
    # 主动标签清洗
    cleaner = ActiveLabelCleaner(
        trainer=deepcopy(trainer),
        dataloader=train_loader,
        noisy_labels=noisy_labels.clone(),
        relabel_budget=relabel_budget,
        train_images=train_images,
        selector_type='cross_entropy'  # 可选'cross_entropy'或'random'
    )
    cleaned_labels = cleaner.clean(test_loader, max_iterations=1)
    
    # 用清洗后标签重新训练
    cleaned_dataset = [(img, label.item()) for img, label in zip(train_images, cleaned_labels)]
    cleaned_loader = DataLoader(cleaned_dataset, batch_size=128, shuffle=True)
    trainer.train(cleaned_loader)
    
    # 最终评估
    preds = trainer.predict(test_loader)
    final_acc = accuracy_score(test_dataset.targets, preds)
    results[name] = final_acc
    
    stats = cleaner.simulator.global_stats
    print(f"[{name}] 清洗后准确率: {final_acc:.4f}")
    print(f"[{name}] 提升: {final_acc - before_acc:.4f}")
    print(f"[{name}] 各轮次准确率: {[round(acc, 4) for acc in stats.accuracy]}")
    print("-" * 50)


print("实验结果")
for name in techniques:
    print(f"{name}: 清洗前 {before_cleaning[name]:.4f} -> 清洗后 {results[name]:.4f}, 提升 {results[name] - before_cleaning[name]:.4f}")
```
