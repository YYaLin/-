# 项目周报

**日期**：2025-5-25
**项目实践题目**：面向机器学习的数据清洗方法

## 实践内容
### 思路
1. 数据预处理：对CIFAR-10数据集进行预处理，包括图像大小调整、数据增强和归一化。
2. 加载数据集：将预处理后的CIFAR-10数据集加载到PyTorch中，同时划分训练集和验证集。
3. 生成带噪声的训练标签：对训练集的标签进行一定比例的噪声添加，以模拟真实场景中的标签错误。
4. 训练模型：使用PyTorch训练模型，使用带噪声的训练标签进行训练。
5. 主动标签清洗：使用主动标签清洗方法，对训练集中的噪声标签进行清洗，以提高模型的性能。
   具体方法如下：
   1. 使用函数：LabelDistribution(更新标签)，ActiveLabelSelector(样本选择器，通过ce-H确定综合评分，排序以选择优先清洗数据),DataCurationSimulator(模拟人工标注)
   2. 流程：
      1. 初始化：初始化标签分布、样本选择器和数据标注器。
      2. 迭代：
         1. 选择样本：使用样本选择器选择一批待清洗的样本。
         2. 模拟标注：使用数据标注器模拟人工标注过程，生成新的标签。
         3. 更新标签：使用标签分布更新标签。
         4. 重复：重复上述步骤，直到达到预设的清洗预算。
6. 重新训练和评估：使用清洗后的标签重新训练模型，并评估模型在测试集上的性能。
7. 输出结果：输出清洗前后的准确率对比。
### 论文代码
**数据预处理**
```python
transform_train = transforms.Compose([
    transforms.Resize(128),
    transforms.RandomHorizontalFlip(),
    transforms.RandomVerticalFlip(),
    transforms.RandomRotation(30),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
transform_test = transforms.Compose([
    transforms.Resize(128),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
```

**加载数据集，划分集合并添加噪声标签**
```python
full_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)

# 划分训练集和验证集（80%训练，20%验证）
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_data, val_data = random_split(full_dataset, [train_size, val_size])

# 生成带噪声的训练标签
train_images = [data[0] for data in train_data]
true_labels = torch.tensor([data[1] for data in train_data])
noisy_labels = true_labels.clone()
noise_rate = 0.3
n_noisy = int(len(noisy_labels) * noise_rate)
noisy_indices = torch.randperm(len(noisy_labels))[:n_noisy]
for idx in noisy_indices:
    # 随机替换为其他类别标签
    new_label = torch.randint(0, 10, (1,))
    while new_label == noisy_labels[idx]:
        new_label = torch.randint(0, 10, (1,))
    noisy_labels[idx] = new_label
```
**训练函数**
首先进行清洗前训练，然后进行主动标签清洗，最后进行清洗后训练。
输出清洗前后的准确率对比
```python
for name, trainer in techniques.items():
    # if(name == 'Vanilla'): continue
    # if(name == 'CoTeaching'): continue
    # if(name == 'ELR'): continue
    print(f"--------{name}--------")

    # 初始训练（带噪声标签）
    trainer.train(train_loader)
    preds = trainer.predict(test_loader)
    before_acc = accuracy_score(test_dataset.targets, preds)
    before_cleaning[name] = before_acc
    print(f"[{name}] 清洗前准确率: {before_acc:.4f}")
    
    print(f"--------[{name}]主动标签清洗--------")
    # 主动标签清洗
    cleaner = ActiveLabelCleaner(
        trainer=deepcopy(trainer),
        dataloader=train_loader,
        noisy_labels=noisy_labels.clone(),
        relabel_budget=relabel_budget,
        train_images=train_images,
        selector_type='cross_entropy'  # 可选'cross_entropy'或'random'
    )
    cleaned_labels = cleaner.clean(test_loader, max_iterations=5)
    
    print(f"--------[{name}]重新训练并且评估--------")
    # 用清洗后标签重新训练
    cleaned_dataset = [(img, label.item()) for img, label in zip(train_images, cleaned_labels)]
    cleaned_loader = DataLoader(cleaned_dataset, batch_size=128, shuffle=True)
    trainer.train(cleaned_loader)
    
    # 最终评估
    preds = trainer.predict(test_loader)
    final_acc = accuracy_score(test_dataset.targets, preds)
    results[name] = final_acc
    
    stats = cleaner.simulator.global_stats
    print(f"[{name}] 清洗后准确率: {final_acc:.4f}")
    print(f"[{name}] 提升: {final_acc - before_acc:.4f}")
    print(f"[{name}] 各轮次准确率: {[round(acc, 4) for acc in stats.accuracy]}")
    print("-" * 50)


print("实验结果")
for name, _ in techniques.items():
    print(f"{name}: 清洗前 {before_cleaning[name]:.4f} -> 清洗后 {results[name]:.4f}, 提升 {results[name] - before_cleaning[name]:.4f}")
```

**开始清洗**
首先初始化标签分布跟模拟器，然后运行模拟，最后获取清洗后的标签
```python
class ActiveLabelCleaner:
    def __init__(self, trainer, dataloader, noisy_labels, relabel_budget, train_images, selector_type='cross_entropy'):
        self.trainer = trainer
        self.dataloader = dataloader
        self.noisy_labels = noisy_labels
        self.relabel_budget = relabel_budget
        self.train_images = train_images
        
        if hasattr(trainer, 'model1') and hasattr(trainer, 'model2'):
            self.selector = ActiveLabelSelector(trainer.model1)
        else:
            self.selector = ActiveLabelSelector(trainer.model)

    
    def clean(self, test_loader, max_iterations=5):
        # 初始化标签分布
        num_classes = 10
        label_dist = LabelDistribution(num_classes)
        
        # 初始化模拟器
        initial_labels = np.eye(num_classes)[self.noisy_labels.numpy()]  # one-hot编码
        simulator = DataCurationSimulator(
            initial_labels=initial_labels,
            label_distribution=label_dist,
            relabel_budget=self.relabel_budget,
            sample_selector=self.selector,
            trainer=self.trainer,
            train_images=self.train_images,
            noisy_labels=self.noisy_labels.numpy()  
        )
        
        # 运行模拟
        simulator.run_simulation(max_iterations=max_iterations, test_loader=test_loader)
        
        # 获取清洗后的标签
        cleaned_labels = simulator.current_labels.argmax(axis=1)
        self.simulator = simulator 
        return cleaned_labels
```

**标签分布**
已知的类别分布为选择的样本分配新标签
```python
class LabelDistribution:
    def __init__(self, num_classes):
        self.num_classes = num_classes
        self.label_counts = np.zeros(num_classes)
        self.distribution = np.ones(num_classes) / num_classes
        self.random_state = np.random.RandomState(42) 
    
    def update_distribution(self, labels):
        unique, counts = np.unique(labels, return_counts=True)
        self.label_counts[unique] += counts
        self.distribution = self.label_counts / self.label_counts.sum()
    
    def sample_labels(self, size):
        return self.random_state.choice(
            self.num_classes,
            size=size,
            p=self.distribution
        )
```
**模拟器**
首先将数据转化为one-hot编码，然后根据选择器选择样本，然后根据综合评分判断是否重新标记，最后构建清洗后的数据集并训练模型
```python
# 数据清洗模拟器
class DataCurationSimulator:
    def __init__(self, initial_labels, label_distribution, 
                 relabel_budget, sample_selector, trainer, train_images, noisy_labels=None):
        self.current_labels = initial_labels  # 初始标签（one-hot编码）
        self.label_distribution = label_distribution  # 真实标签分布
        self.relabel_budget = relabel_budget  # 每次迭代重新标记预算
        self.selector = sample_selector  # 样本选择器
        self.trainer = trainer  # 训练器
        self.train_images = train_images  # 训练图像数据
        self.global_stats = SimulationStats()  # 统计信息
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.noisy_labels = noisy_labels  # 真实的噪声标签
    
    def run_simulation(self, test_loader=None, max_iterations=5):
        for i in range(max_iterations):
            print("--------第{i}次清洗--------".format(i=i+1))
            # 1. 选择需要重新标记的样本
            current_labels = self.current_labels.argmax(axis=1)
            if isinstance(self.selector, ActiveLabelSelector):
                # 创建一个新的DataLoader，包含当前的标签
                train_dataset = [(img, current_labels[i].item()) for i, img in enumerate(self.train_images)]
                train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False)
                
                # 如果有真实的噪声标签，传递给选择器
                if self.noisy_labels is not None:
                    selected_indices, scores = self.selector.select_samples_with_scores(
                        train_loader, self.relabel_budget, self.noisy_labels
                    )
                else:
                    selected_indices, scores = self.selector.select_samples_with_scores(train_loader, self.relabel_budget)
            else:
                selected_indices = self.selector.select_samples(current_labels, self.relabel_budget)
                scores = np.ones(len(selected_indices))  # 如果是随机选择，分数设为1
            
            # 2. 模拟重新标记
            new_labels = []
            for idx, score in zip(selected_indices, scores):
                # 根据评分调整重新标记的概率分布
                adjusted_distribution = self.label_distribution.distribution * score
                adjusted_distribution /= adjusted_distribution.sum()
                new_label = np.random.choice(
                    self.label_distribution.num_classes,
                    p=adjusted_distribution
                )
                new_labels.append(new_label)
            new_labels = np.array(new_labels)
            
            self.current_labels[selected_indices] = np.eye(self.current_labels.shape[1])[new_labels]
            
            # 3. 构建清洗后的数据集并训练模型
            cleaned_labels = self.current_labels.argmax(axis=1)
            cleaned_dataset = [(img, cleaned_labels[i].item()) for i, img in enumerate(self.train_images)]
            cleaned_loader = DataLoader(cleaned_dataset, batch_size=128, shuffle=True)
            self.trainer.train(cleaned_loader)
            
            # 4. 在测试集上评估模型
            if test_loader:
                preds = self.trainer.predict(test_loader)
                accuracy = accuracy_score(test_loader.dataset.targets, preds)
                precision = precision_score(test_loader.dataset.targets, preds, average='macro')
                recall = recall_score(test_loader.dataset.targets, preds, average='macro')
                f1 = f1_score(test_loader.dataset.targets, preds, average='macro')
                
                self.global_stats.update(
                    accuracy=accuracy,
                    precision=precision,
                    recall=recall,
                    f1=f1,
                    selected=len(selected_indices)
                )
            
            # 更新标签分布
            self.label_distribution.update_distribution(cleaned_labels)
```

**样本选择器**
**计算综合评分，并排序选前budget个出来清洗**
```python
class BaseSelector:
    def select_samples(self, labels, budget):
        raise NotImplementedError

class ActiveLabelSelector(BaseSelector):
    def __init__(self, model):
        self.model = model.to(torch.device("cuda" if torch.cuda.is_available() else "cpu"))
    
    def select_samples(self, dataloader, budget, noisy_labels=None):
        # 调用 select_samples_with_scores 方法并只返回索引
        selected_indices, _ = self.select_samples_with_scores(dataloader, budget, noisy_labels)
        return selected_indices
    
    def select_samples_with_scores(self, dataloader, budget, noisy_labels=None):
        #评分函数 Φ = 交叉熵（噪声）- 熵（难度），选择评分最高的样本
        self.model.eval()
        ce_scores = []  # 交叉熵（噪声分数）
        entropy_scores = []  # 熵（难度分数）
        device = next(self.model.parameters()).device
        
        with torch.no_grad():
            for i, (images, labels) in enumerate(dataloader):
                images = images.to(device)
                outputs = self.model(images)
                probs = F.softmax(outputs, dim=1)
                
                # 计算交叉熵（CE）：-log(p(y|x))，y为真实的噪声标签
                if noisy_labels is not None:
                    # 获取当前批次的噪声标签
                    batch_size = images.size(0)
                    start_idx = i * batch_size
                    end_idx = min(start_idx + batch_size, len(noisy_labels))
                    batch_noisy_labels = torch.tensor(noisy_labels[start_idx:end_idx]).to(device)
                    
                    # 计算交叉熵
                    ce = -torch.log(probs[torch.arange(len(batch_noisy_labels)), batch_noisy_labels] + 1e-8)
                else:
                    # 如果没有提供噪声标签，使用模型预测的伪标签
                    pseudo_labels = probs.argmax(dim=1)
                    ce = -torch.log(probs[torch.arange(len(pseudo_labels)), pseudo_labels] + 1e-8)
                
                ce_scores.extend(ce.cpu().numpy())
                
                # 计算熵（H）：-Σp(c|x)log(p(c|x))
                entropy = -torch.sum(probs * torch.log(probs + 1e-8), dim=1)
                entropy_scores.extend(entropy.cpu().numpy())
        
        # 综合评分：CE-H（论文公式2）
        scores = np.array(ce_scores) - np.array(entropy_scores)
        selected_indices = np.argsort(-scores)[:budget]  # 降序排列，选前budget个
        selected_scores = scores[selected_indices]
        return selected_indices, selected_scores
```

**记录结果**
```python
class SimulationStats:
    def __init__(self):
        self.iterations = 0
        self.accuracy = []
        self.precision = []
        self.recall = []
        self.f1_score = []
        self.selected_counts = []
    
    def update(self, accuracy, precision, recall, f1, selected):
        self.iterations += 1
        self.accuracy.append(accuracy)
        self.precision.append(precision)
        self.recall.append(recall)
        self.f1_score.append(f1)
        self.selected_counts.append(selected)
```

### 结果
``` python
每个方法清洗5轮，每轮10次，结果如下：
[Vanilla] 清洗前准确率: 0.6497
[Vanilla] 清洗后准确率: 0.6367
[Vanilla] 提升: -0.0130
[Vanilla] 各轮次准确率: [0.6587, 0.6323, 0.643, 0.6527, 0.6483]

[CoTeaching] 清洗前准确率: 0.8085
[CoTeaching] 清洗后准确率: 0.7946
[CoTeaching] 提升: -0.0139
[CoTeaching] 各轮次准确率: [0.8004, 0.8048, 0.7911, 0.7849, 0.7956]

[ELR] 清洗前准确率: 0.6722
[ELR] 清洗后准确率: 0.6584
[ELR] 提升: -0.0138
[ELR] 各轮次准确率: [0.6278, 0.6513, 0.6297, 0.6498, 0.6606]

实验结果
Vanilla: 清洗前 0.6497 -> 清洗后 0.6367, 提升 -0.0130
CoTeaching: 清洗前 0.8085 -> 清洗后 0.7946, 提升 -0.0139
ELR: 清洗前 0.6722 -> 清洗后 0.6584, 提升 -0.0138
```