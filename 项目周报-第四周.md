# 项目周报

**日期**：2025-4-27  
**项目实践题目**：面向机器学习的数据清洗方法

## 实践内容
### **1. 数据集（Datasets）**  
论文使用了两个数据集进行实验，分别涵盖自然图像和医疗影像：  

### **(1) CIFAR10H**  
- **来源**：CIFAR10 的测试集（10,000 张图像），每张图有约51个众包标注（共10类）
- **噪声模拟**：  
  - 初始噪声标签通过从真实标注分布中采样生成。  
  - 使用 **温度缩放（Temperature Scaling, τ）** 控制噪声率（τ 越高，噪声越强）
  - 样本难度分类：
    - 若该分布的熵高于特定阈值（本实验中为 0.3），则样本被归类为“困难样本”
### **(2) NoisyCXR（医学影像数据集）**  
- **来源**：基于 NIH ChestX-ray 数据集，包含 26,684 张胸部 X 光片，标签由 **NLP** 自动提取（存在噪声） 
- **噪声模拟**：  
  - 原始 NIH 标签（自动提取）与 RSNA 专家标注对比，构建噪声映射（如“肺炎” vs “非肺炎”）
  - **样本难度分类**：  
    - **易样本**：高置信度标注（如明确肺炎病灶）
    - **难样本**：低置信度或存在争议（如轻微异常，不同医生意见不一）
---

### **2. 噪声鲁棒学习**  
为了在噪声数据上训练可靠的分类器（用于后续标签清洗），论文采用了三种方法：  

### **(1) 标准训练（Vanilla）**  
- 普通 CNN（ResNet-50）+ 交叉熵损失（CE Loss）
- **问题**：会受噪声标签影响而产生偏差，在样本重标记优先级排序中表现欠佳 

### **(2) 协同教学**  
- **核心思想**：两个独立初始化的模型互相筛选低损失样本进行训练，避免噪声记忆，定义两个初始化不同但结构相同的网络同步训练
- **流程**：  
  1. 模型 A 选择损失低的样本给模型 B 训练，反之亦然  
  2. 最终预测采用两个模型的平均（Ensemble）
- **优点**：减少噪声样本的影响，提高鲁棒性，在分类准确性和鲁棒性方面表现出色

### **(3) 自监督学习**  
- **原因**：NRL 仍可能受到标签噪声的影响并排除困难样本，因为这些样本会产生较大的损失值。在能够定义辅助任务预训练模型时进一步提升样本排序性能。还可以与协同教学算法以端到端方式结合使用.
- **方法**：自监督学习（SSL）不依赖于标签，嵌入表示将仅基于图像内容生成，使得相似图像在嵌入空间中距离相近，不相似图像则相距较远。采用 **BYOL** 进行无监督预训练，再微调分类器
  - 先训练编码器（仅用图像，无标签） 
  - 然后固定gθ，训练线性分类器  
  - 为获得校准性更好的后验概率，训练时通过惩罚函数抑制较大逻辑值
- **优点**：  
  - 避免标签噪声对特征学习的干扰
  - 能够增强模型对错误标签的鲁棒性 

---

### **3. 样本选择算法（Sample Selection）**  
核心目标是 **优先选择最可能错误的样本进行重新标注**，论文提出了一种 **评分函数 Φ**：  

$$
\Phi(x, \hat{l}; \theta) = \underbrace{\text{CE}(\hat{l}, p_\theta)}_{\text{标签噪声程度}} - \underbrace{\text{H}(p_\theta)}_{\text{样本模糊性}}
$$

- **CE（交叉熵）**：衡量当前标注 \(\hat{l}\) 与模型预测 \(p_\theta(y|x)\) 的不一致性（高 CE → 可能错误）。  
- **H（熵）**：衡量模型预测的模糊性（高熵 → 样本本身难分类，可能需多次标注）。  

**排序策略**：  
1. **高 CE + 低 H** → **明显错误**（优先清洗）。  
2. **高 CE + 高 H** → **模糊样本**（需更多标注，成本高，优先级较低）。  
3. **低 CE** → **可能正确**（不优先清洗）。  

---

### **4. 标签清洗流程**  
采用 **迭代式清洗**，具体步骤如下（对应 Algorithm 1）：  

1. **初始化**：  
   - 输入：带噪声的数据集 \(\mathcal{D} = \{(x_i, \hat{l}_i)\}\)，标注预算 \(B\)。  
   - 训练初始噪声鲁棒模型 \(p_\theta(y|x)\)（如 Co-Teaching 或 SSL）。  

2. **迭代清洗**（直到预算耗尽）：  
- 标签清洗通过多次迭代进行，每次迭代中单个或批量样本会被重新标记
- 在单次迭代内，计算所有样本的 \(\Phi(x, \hat{l}; \theta)\)，按标注难度进行排列
- 取排名最高的样本 \(x_i\)，标注 
- 如果新标注与旧标签不同，更新 \(\hat{l}_i\)，如果仍无共识，继续标注直到所有标签形成多数共识  
- 下一轮迭代中，剩余样本会被重新排序，该过程重复进行直至重标记预算耗尽  

---

### **问题**
虽然知道了大概原理，但是不知道具体代码框架如何实现，我看了他的代码仓库，但是很杂乱，不知道从哪入手。不知道他各个模型怎么联动起来
[InnerEye-DataQuality](https://github.com/microsoft/InnerEye-DeepLearning/tree/1606729c7a16e1bfeb269694314212b6e2737939/InnerEye-DataQuality/InnerEyeDataQuality)