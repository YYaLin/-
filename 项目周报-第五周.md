# 项目周报

**日期**：2025-5-11
**项目实践题目**：面向机器学习的数据清洗方法

## 实践内容
### 支线
```python
from openai import OpenAI

client = OpenAI(api_key="自己的key", 
                base_url="https://api.siliconflow.cn/v1")
response = client.chat.completions.create(
    model="模型名称",
    messages=[
        {'role': 'user', 
        'content': "内容"}
    ],
    stream=True
)

for chunk in response:
    if not chunk.choices:
        continue
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
    if chunk.choices[0].delta.reasoning_content:
        print(chunk.choices[0].delta.reasoning_content, end="", flush=True)
```
**回答：** Hello! It seems like your message is a friendly comment. How can I assist you today? If you have any questions or need help with something, feel free to ask!😊

### 论文简单代码编写
把数据集D随机污染里面5%的标签得到D’，来测试各个技术的检测效果
### 准备数据集
**数据集CIFAR-10**
**加载数据集并预处理**
```python
# 加载并预处理
train_trans_img = transforms.Compose([
    transforms.Resize(128),
    transforms.RandomVerticalFlip(),
    transforms.RandomHorizontalFlip(),
    transforms.RandomChoice([
        transforms.RandomRotation(90),
        transforms.RandomRotation(180),
        transforms.RandomRotation(270)
    ]),
    transforms.RandomResizedCrop(128, (0.8, 1.0)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                            [0.229, 0.224, 0.225])
])

test_trans_img = transforms.Compose([
    transforms.Resize(128),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                            std=[0.229, 0.224, 0.225])
])

#CIFAR-10
full_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=None)
test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_trans_img)

#划分
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

# transform
train_dataset = [(train_trans_img(img), label) for img, label in train_dataset]
val_dataset = [(test_trans_img(img), label) for img, label in val_dataset]
```

**添加噪声**
```python
def add_noise(labels, noise_rate=0.05, num_classes=10):
    noisy_labels = labels.clone()
    n_noisy = int(noise_rate * len(labels))
    noisy_indices = torch.randperm(len(labels))[:n_noisy]
    for idx in noisy_indices:
        noisy_labels[idx] = torch.randint(0, num_classes, (1,))
    return noisy_labels
```
### 加载模型
**ResNet18**
```python
class ResNet18(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.model = resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)
    def forward(self, x):
        return self.model(x)
```

### 测试方法
**基准方法**
```python
# Vanilla
class VanillaTrainer:
    def __init__(self, config=None):
        self.model = ResNet18().cuda()
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-3)
        self.tanh_regularisation = 0.0  # tanh正则化
        self.device = torch.device("cuda")

    def train(self, dataloader):
        self.model.train()
        for images, labels in tqdm(dataloader, desc="Vanilla Training"):
            images, labels = images.to(self.device), labels.to(self.device)
            outputs = self.model(images)
            
            # 计算损失
            per_sample_loss = self.criterion(outputs, labels)
            loss = torch.mean(per_sample_loss)
            
            # tanh正则化
            if self.tanh_regularisation != 0.0:
                loss += self.tanh_regularisation * torch.mean(torch.tanh(outputs)**2)
            
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

    def predict(self, dataloader):
        self.model.eval()
        preds = []
        with torch.no_grad():
            for images, _ in tqdm(dataloader, desc="Vanilla Predict"):
                images = images.to(self.device)
                outputs = self.model(images)
                preds.extend(outputs.argmax(dim=1).cpu().numpy())
        return np.array(preds)
```
**协同训练**
```python
# CoTeaching
class CoTeachingTrainer:
    def __init__(self, config=None):
        self.model1 = ResNet18().cuda()
        self.model2 = ResNet18().cuda()
        self.criterion = nn.CrossEntropyLoss(reduction='none')
        self.optimizer1 = optim.Adam(self.model1.parameters(), lr=1e-3)
        self.optimizer2 = optim.Adam(self.model2.parameters(), lr=1e-3)

    def train(self, dataloader, epochs=5, keep_ratio=0.8):
        for epoch in range(epochs):
            self.model1.train()
            self.model2.train()
            print(f"Epoch {epoch+1}/{epochs}")
            for images, labels in tqdm(dataloader, desc="CoTeaching Training"):
                images, labels = images.cuda(), labels.cuda()
                logits1 = self.model1(images)
                logits2 = self.model2(images)

                loss1 = self.criterion(logits1, labels)
                loss2 = self.criterion(logits2, labels)

                # 选择损失较小的样本（更有可能是干净的）
                idx1 = torch.argsort(loss1)[:int(len(loss1) * keep_ratio)]
                idx2 = torch.argsort(loss2)[:int(len(loss2) * keep_ratio)]

                # 模型1用模型2选的样本训练，反之亦然
                self.optimizer1.zero_grad()
                loss = self.criterion(self.model1(images[idx2]), labels[idx2]).mean()
                loss.backward()
                self.optimizer1.step()

                self.optimizer2.zero_grad()
                loss = self.criterion(self.model2(images[idx1]), labels[idx1]).mean()
                loss.backward()
                self.optimizer2.step()

    def predict(self, dataloader):
        self.model1.eval()
        self.model2.eval()
        preds = []
        with torch.no_grad():
            for images, _ in tqdm(dataloader, desc="CoTeaching Predict"):
                images = images.cuda()
                out1 = self.model1(images)
                out2 = self.model2(images)
                avg_out = (out1 + out2) / 2
                preds.extend(avg_out.argmax(dim=1).cpu().numpy())
        return np.array(preds)
```
**早期学习正则化（继承基准方法）**
```python
class ELRTrainer(VanillaTrainer):
    def __init__(self, config=None):
        super().__init__(config)
        self.num_classes = 10
        self.targets = torch.zeros(len(train_dataset), self.num_classes).cuda()
        self.beta = 0.9
        self._lambda = 3

    def train(self, dataloader, epochs=5):
        self.model.train()
        for epoch in range(epochs):
            print(f"Epoch {epoch+1}/{epochs}")
            for batch_idx, (images, labels) in enumerate(tqdm(dataloader, desc="ELR Training")):
                images, labels = images.cuda(), labels.cuda()
                indices = torch.arange(batch_idx * dataloader.batch_size, 
                                     min((batch_idx + 1) * dataloader.batch_size, len(train_dataset)))
                
                outputs = self.model(images)
                y_pred = F.softmax(outputs, dim=1)
                y_pred = torch.clamp(y_pred, 1e-4, 1.0 - 1e-4)
                
                # 更新目标记忆
                with torch.no_grad():
                    y_pred_ = y_pred.detach()
                    self.targets[indices] = self.beta * self.targets[indices] + (1 - self.beta) * (
                        y_pred_ / y_pred_.sum(dim=1, keepdim=True))
                
                # 计算ELR损失
                ce_loss = F.cross_entropy(outputs, labels, reduction="none")
                elr_reg = (1 - (self.targets[indices] * y_pred).sum(dim=1)).log()
                loss = (ce_loss + self._lambda * elr_reg).mean()
                
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

    def predict(self, dataloader):
        self.model.eval()
        preds = []
        with torch.no_grad():
            for images, _ in tqdm(dataloader, desc="ELR Predict"):
                images = images.cuda()
                outputs = self.model(images)
                preds.extend(outputs.argmax(dim=1).cpu().numpy())
        return np.array(preds)
```
### 运行主代码
```python
techniques = {
    'Vanilla': VanillaTrainer(),
    'CoTeaching': CoTeachingTrainer(),
    'ELR': ELRTrainer()
}

results = {}
for name, trainer in techniques.items():
    print(f"Training with {name}...")
    trainer.train(train_loader)
    preds = trainer.predict(test_loader)
    labels = np.array(test_dataset.targets)
    acc = (preds == labels).mean()
    results[name] = acc

print("\n标签准确率:")
for name, acc in results.items():
    print(f"{name}: {acc:.4f}")
```
### 训练结果
标签准确率:
Vanilla: 0.6163
CoTeaching: 0.7400
ELR: 0.6931
**修改时发现好像写的有问题，跟标签清洗没什么关系，只是拿图片经过模型训练后，去预测集的预测标签跟原先标签对比，是这样吗？后面改进**