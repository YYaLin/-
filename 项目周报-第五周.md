# é¡¹ç›®å‘¨æŠ¥

**æ—¥æœŸ**ï¼š2025-5-11
**é¡¹ç›®å®è·µé¢˜ç›®**ï¼šé¢å‘æœºå™¨å­¦ä¹ çš„æ•°æ®æ¸…æ´—æ–¹æ³•

## å®è·µå†…å®¹
### æ”¯çº¿
```python
from openai import OpenAI

client = OpenAI(api_key="è‡ªå·±çš„key", 
                base_url="https://api.siliconflow.cn/v1")
response = client.chat.completions.create(
    model="æ¨¡å‹åç§°",
    messages=[
        {'role': 'user', 
        'content': "å†…å®¹"}
    ],
    stream=True
)

for chunk in response:
    if not chunk.choices:
        continue
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
    if chunk.choices[0].delta.reasoning_content:
        print(chunk.choices[0].delta.reasoning_content, end="", flush=True)
```
**å›ç­”ï¼š** Hello! It seems like your message is a friendly comment. How can I assist you today? If you have any questions or need help with something, feel free to ask!ğŸ˜Š

### è®ºæ–‡ç®€å•ä»£ç ç¼–å†™
æŠŠæ•°æ®é›†Déšæœºæ±¡æŸ“é‡Œé¢5%çš„æ ‡ç­¾å¾—åˆ°Dâ€™ï¼Œæ¥æµ‹è¯•å„ä¸ªæŠ€æœ¯çš„æ£€æµ‹æ•ˆæœ
### å‡†å¤‡æ•°æ®é›†
**æ•°æ®é›†CIFAR-10**
**åŠ è½½æ•°æ®é›†å¹¶é¢„å¤„ç†**
```python
# åŠ è½½å¹¶é¢„å¤„ç†
train_trans_img = transforms.Compose([
    transforms.Resize(128),
    transforms.RandomVerticalFlip(),
    transforms.RandomHorizontalFlip(),
    transforms.RandomChoice([
        transforms.RandomRotation(90),
        transforms.RandomRotation(180),
        transforms.RandomRotation(270)
    ]),
    transforms.RandomResizedCrop(128, (0.8, 1.0)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                            [0.229, 0.224, 0.225])
])

test_trans_img = transforms.Compose([
    transforms.Resize(128),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                            std=[0.229, 0.224, 0.225])
])

#CIFAR-10
full_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=None)
test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_trans_img)

#åˆ’åˆ†
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

# transform
train_dataset = [(train_trans_img(img), label) for img, label in train_dataset]
val_dataset = [(test_trans_img(img), label) for img, label in val_dataset]
```

**æ·»åŠ å™ªå£°**
```python
def add_noise(labels, noise_rate=0.05, num_classes=10):
    noisy_labels = labels.clone()
    n_noisy = int(noise_rate * len(labels))
    noisy_indices = torch.randperm(len(labels))[:n_noisy]
    for idx in noisy_indices:
        noisy_labels[idx] = torch.randint(0, num_classes, (1,))
    return noisy_labels
```
### åŠ è½½æ¨¡å‹
**ResNet18**
```python
class ResNet18(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.model = resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)
    def forward(self, x):
        return self.model(x)
```

### æµ‹è¯•æ–¹æ³•
**åŸºå‡†æ–¹æ³•**
```python
# Vanilla
class VanillaTrainer:
    def __init__(self, config=None):
        self.model = ResNet18().cuda()
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-3)
        self.tanh_regularisation = 0.0  # tanhæ­£åˆ™åŒ–
        self.device = torch.device("cuda")

    def train(self, dataloader):
        self.model.train()
        for images, labels in tqdm(dataloader, desc="Vanilla Training"):
            images, labels = images.to(self.device), labels.to(self.device)
            outputs = self.model(images)
            
            # è®¡ç®—æŸå¤±
            per_sample_loss = self.criterion(outputs, labels)
            loss = torch.mean(per_sample_loss)
            
            # tanhæ­£åˆ™åŒ–
            if self.tanh_regularisation != 0.0:
                loss += self.tanh_regularisation * torch.mean(torch.tanh(outputs)**2)
            
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

    def predict(self, dataloader):
        self.model.eval()
        preds = []
        with torch.no_grad():
            for images, _ in tqdm(dataloader, desc="Vanilla Predict"):
                images = images.to(self.device)
                outputs = self.model(images)
                preds.extend(outputs.argmax(dim=1).cpu().numpy())
        return np.array(preds)
```
**ååŒè®­ç»ƒ**
```python
# CoTeaching
class CoTeachingTrainer:
    def __init__(self, config=None):
        self.model1 = ResNet18().cuda()
        self.model2 = ResNet18().cuda()
        self.criterion = nn.CrossEntropyLoss(reduction='none')
        self.optimizer1 = optim.Adam(self.model1.parameters(), lr=1e-3)
        self.optimizer2 = optim.Adam(self.model2.parameters(), lr=1e-3)

    def train(self, dataloader, epochs=5, keep_ratio=0.8):
        for epoch in range(epochs):
            self.model1.train()
            self.model2.train()
            print(f"Epoch {epoch+1}/{epochs}")
            for images, labels in tqdm(dataloader, desc="CoTeaching Training"):
                images, labels = images.cuda(), labels.cuda()
                logits1 = self.model1(images)
                logits2 = self.model2(images)

                loss1 = self.criterion(logits1, labels)
                loss2 = self.criterion(logits2, labels)

                # é€‰æ‹©æŸå¤±è¾ƒå°çš„æ ·æœ¬ï¼ˆæ›´æœ‰å¯èƒ½æ˜¯å¹²å‡€çš„ï¼‰
                idx1 = torch.argsort(loss1)[:int(len(loss1) * keep_ratio)]
                idx2 = torch.argsort(loss2)[:int(len(loss2) * keep_ratio)]

                # æ¨¡å‹1ç”¨æ¨¡å‹2é€‰çš„æ ·æœ¬è®­ç»ƒï¼Œåä¹‹äº¦ç„¶
                self.optimizer1.zero_grad()
                loss = self.criterion(self.model1(images[idx2]), labels[idx2]).mean()
                loss.backward()
                self.optimizer1.step()

                self.optimizer2.zero_grad()
                loss = self.criterion(self.model2(images[idx1]), labels[idx1]).mean()
                loss.backward()
                self.optimizer2.step()

    def predict(self, dataloader):
        self.model1.eval()
        self.model2.eval()
        preds = []
        with torch.no_grad():
            for images, _ in tqdm(dataloader, desc="CoTeaching Predict"):
                images = images.cuda()
                out1 = self.model1(images)
                out2 = self.model2(images)
                avg_out = (out1 + out2) / 2
                preds.extend(avg_out.argmax(dim=1).cpu().numpy())
        return np.array(preds)
```
**æ—©æœŸå­¦ä¹ æ­£åˆ™åŒ–ï¼ˆç»§æ‰¿åŸºå‡†æ–¹æ³•ï¼‰**
```python
class ELRTrainer(VanillaTrainer):
    def __init__(self, config=None):
        super().__init__(config)
        self.num_classes = 10
        self.targets = torch.zeros(len(train_dataset), self.num_classes).cuda()
        self.beta = 0.9
        self._lambda = 3

    def train(self, dataloader, epochs=5):
        self.model.train()
        for epoch in range(epochs):
            print(f"Epoch {epoch+1}/{epochs}")
            for batch_idx, (images, labels) in enumerate(tqdm(dataloader, desc="ELR Training")):
                images, labels = images.cuda(), labels.cuda()
                indices = torch.arange(batch_idx * dataloader.batch_size, 
                                     min((batch_idx + 1) * dataloader.batch_size, len(train_dataset)))
                
                outputs = self.model(images)
                y_pred = F.softmax(outputs, dim=1)
                y_pred = torch.clamp(y_pred, 1e-4, 1.0 - 1e-4)
                
                # æ›´æ–°ç›®æ ‡è®°å¿†
                with torch.no_grad():
                    y_pred_ = y_pred.detach()
                    self.targets[indices] = self.beta * self.targets[indices] + (1 - self.beta) * (
                        y_pred_ / y_pred_.sum(dim=1, keepdim=True))
                
                # è®¡ç®—ELRæŸå¤±
                ce_loss = F.cross_entropy(outputs, labels, reduction="none")
                elr_reg = (1 - (self.targets[indices] * y_pred).sum(dim=1)).log()
                loss = (ce_loss + self._lambda * elr_reg).mean()
                
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

    def predict(self, dataloader):
        self.model.eval()
        preds = []
        with torch.no_grad():
            for images, _ in tqdm(dataloader, desc="ELR Predict"):
                images = images.cuda()
                outputs = self.model(images)
                preds.extend(outputs.argmax(dim=1).cpu().numpy())
        return np.array(preds)
```
### è¿è¡Œä¸»ä»£ç 
```python
techniques = {
    'Vanilla': VanillaTrainer(),
    'CoTeaching': CoTeachingTrainer(),
    'ELR': ELRTrainer()
}

results = {}
for name, trainer in techniques.items():
    print(f"Training with {name}...")
    trainer.train(train_loader)
    preds = trainer.predict(test_loader)
    labels = np.array(test_dataset.targets)
    acc = (preds == labels).mean()
    results[name] = acc

print("\næ ‡ç­¾å‡†ç¡®ç‡:")
for name, acc in results.items():
    print(f"{name}: {acc:.4f}")
```
### è®­ç»ƒç»“æœ
æ ‡ç­¾å‡†ç¡®ç‡:
Vanilla: 0.6163
CoTeaching: 0.7400
ELR: 0.6931
**ä¿®æ”¹æ—¶å‘ç°å¥½åƒå†™çš„æœ‰é—®é¢˜ï¼Œè·Ÿæ ‡ç­¾æ¸…æ´—æ²¡ä»€ä¹ˆå…³ç³»ï¼Œåªæ˜¯æ‹¿å›¾ç‰‡ç»è¿‡æ¨¡å‹è®­ç»ƒåï¼Œå»é¢„æµ‹é›†çš„é¢„æµ‹æ ‡ç­¾è·ŸåŸå…ˆæ ‡ç­¾å¯¹æ¯”ï¼Œæ˜¯è¿™æ ·å—ï¼Ÿåé¢æ”¹è¿›**